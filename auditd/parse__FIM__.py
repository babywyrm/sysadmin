#!/usr/bin/env python3
"""
parse_fim.py - Advanced Auditd Log Parser for File Integrity Monitoring (FIM)

This script is designed to parse auditd logs for FIM events. It is especially
useful in environments where file integrity is monitored using auditd rules.
It supports:

  • Parsing multiple audit log files (plain text or gzip‑compressed).
  • Filtering by audit record key (default "fim"), file path patterns (regex),
    syscalls, and time ranges.
  • Output in plain text, JSON, or CSV.

FIM events are typically generated by auditd when file changes occur. For example:

  On Ubuntu:
    1. Install auditd:
         sudo apt-get install auditd
    2. Create a FIM rule (e.g., in /etc/audit/rules.d/fim.rules):
         -w /etc/passwd -p wa -k fim
    3. Restart auditd:
         sudo service auditd restart

  On Red Hat:
    1. Ensure auditd is installed:
         sudo yum install audit
    2. Add a rule via auditctl (or in /etc/audit/audit.rules):
         auditctl -w /etc/passwd -p wa -k fim
    3. Restart auditd:
         sudo systemctl restart auditd

Usage Examples:
  # Parse the default audit log for FIM events (plain text output):
  python3 parse_fim.py

  # Parse specific log files and filter events with key "fim":
  python3 parse_fim.py --files "/var/log/audit/audit.log,/var/log/audit/audit.log.1" --filter-key fim

  # Filter events for file paths matching '/etc/' and output JSON:
  python3 parse_fim.py --filter-key fim --filter-path "/etc/" --output-format json

  # Filter by syscall (e.g., unlink) and output CSV:
  python3 parse_fim.py --filter-syscall unlink --output-format csv --output-file fim_events.csv
"""
import argparse
import json
import csv
import os,sys,re
import logging
import gzip
import datetime

def open_log_file(filename):
    """Open a log file; if the file ends with .gz, open as gzip."""
    if filename.endswith('.gz'):
        return gzip.open(filename, 'rt', encoding='utf-8', errors='replace')
    else:
        return open(filename, 'r', encoding='utf-8', errors='replace')

def parse_audit_line(line):
    """
    Parse a single auditd log line.
    
    Expected format (example):
      type=PATH msg=audit(1611272033.562:104): item=0 name="/etc/passwd" inode=123456 ...
    or
      type=SYSCALL msg=audit(1611272033.562:105): arch=c000003e syscall=unlink success=yes exit=0 ...
      
    Returns a dictionary of the parsed fields, or None if the line does not match.
    """
    pattern = r'^type=(?P<type>\S+)\s+msg=audit\((?P<timestamp>[0-9.]+):(?P<id>\d+)\):\s*(?P<kvpairs>.*)$'
    m = re.match(pattern, line)
    if not m:
        return None

    data = m.groupdict()
    kvpairs = data.pop('kvpairs', '')
    
    # Regex to capture key=value pairs (handles quoted values)
    kv_pattern = re.compile(r'(\w+)=(".*?"|\S+)')
    fields = {}
    for match in kv_pattern.finditer(kvpairs):
        key = match.group(1)
        value = match.group(2)
        if value.startswith('"') and value.endswith('"'):
            value = value[1:-1]
        fields[key] = value

    data.update(fields)
    return data

def parse_time(timestamp_str):
    """Convert a timestamp string (epoch seconds) to a float."""
    try:
        return float(timestamp_str)
    except Exception:
        return None

def filter_fim_record(record, args):
    """
    Apply FIM-specific filters to a parsed audit record.
    
    Filters include:
      - Key filter (e.g., only include records with key "fim")
      - File path filter: regex matching on the 'name' field (if present)
      - Syscall filter: on the 'syscall' field (if provided)
      - Time range filter (using the timestamp field)
    """
    # By default, we want FIM events. Audit rules typically add a "key" field.
    if args.filter_key:
        # Some records may not have a key; if missing, skip
        if record.get("key") != args.filter_key:
            return False

    # Filter by file path: check the 'name' field if provided.
    if args.filter_path:
        file_path = record.get("name", "")
        if not re.search(args.filter_path, file_path):
            return False

    # Filter by syscall (e.g., unlink, open, etc.)
    if args.filter_syscall:
        if record.get("syscall") != args.filter_syscall:
            return False

    # Filter by time range (timestamps are in epoch seconds)
    if args.time_start or args.time_end:
        t = parse_time(record.get("timestamp"))
        if t is None:
            return False
        if args.time_start and t < args.time_start:
            return False
        if args.time_end and t > args.time_end:
            return False

    return True

def output_records(records, args):
    """Output the parsed FIM records in the chosen format (plain, json, or csv)."""
    if args.output_format == "json":
        output = json.dumps(records, indent=2)
        if args.output_file:
            with open(args.output_file, "w", encoding="utf-8") as f:
                f.write(output)
        else:
            print(output)
    elif args.output_format == "csv":
        # Determine header from union of all keys
        keys = set()
        for rec in records:
            keys.update(rec.keys())
        keys = sorted(list(keys))
        if args.output_file:
            fout = open(args.output_file, "w", newline="", encoding="utf-8")
        else:
            fout = sys.stdout
        writer = csv.DictWriter(fout, fieldnames=keys)
        writer.writeheader()
        for rec in records:
            writer.writerow(rec)
        if args.output_file:
            fout.close()
    else:
        # Plain text output
        for rec in records:
            timestamp = rec.get("timestamp", "")
            audit_type = rec.get("type", "")
            audit_id = rec.get("id", "")
            try:
                ts_float = float(timestamp)
                dt = datetime.datetime.fromtimestamp(ts_float).strftime("%Y-%m-%d %H:%M:%S")
            except Exception:
                dt = timestamp
            # If the record contains a file name, include it
            file_info = ""
            if "name" in rec:
                file_info = f" File: {rec['name']}"
            # Include syscall if present
            syscall_info = ""
            if "syscall" in rec:
                syscall_info = f" Syscall: {rec['syscall']}"
            # Also include any key field
            key_info = ""
            if "key" in rec:
                key_info = f" Key: {rec['key']}"
            print(f"[{dt}] {audit_type} (id={audit_id}){file_info}{syscall_info}{key_info}")

def main():
    parser = argparse.ArgumentParser(
        description="Parse auditd logs for File Integrity Monitoring (FIM) events."
    )
    parser.add_argument(
        "--files", "-f",
        type=str,
        default="/var/log/audit/audit.log",
        help=("Comma-separated list of audit log files to parse. "
              "Defaults to '/var/log/audit/audit.log'.")
    )
    parser.add_argument(
        "--filter-key",
        type=str,
        default="fim",
        help=("Filter events by audit rule key (default: 'fim'). "
              "Use the key you set in your audit rules for FIM.")
    )
    parser.add_argument(
        "--filter-path",
        type=str,
        help=("Regular expression to filter events by file path. "
              "Matches against the 'name' field in PATH events.")
    )
    parser.add_argument(
        "--filter-syscall",
        type=str,
        help="Filter events by syscall (e.g., unlink, open, chmod)."
    )
    parser.add_argument(
        "--time-start",
        type=float,
        help="Filter records with timestamp >= this epoch value."
    )
    parser.add_argument(
        "--time-end",
        type=float,
        help="Filter records with timestamp <= this epoch value."
    )
    parser.add_argument(
        "--output-format",
        choices=["plain", "json", "csv"],
        default="plain",
        help="Output format: plain (default), json, or csv."
    )
    parser.add_argument(
        "--output-file",
        type=str,
        help="Optional file to write output to; otherwise output is printed to stdout."
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging for debugging."
    )
    args = parser.parse_args()

    # Configure logging level
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(level=log_level, format="[%(levelname)s] %(message)s")

    # Split the files argument by comma
    file_list = [f.strip() for f in args.files.split(",")]
    all_records = []

    for file_path in file_list:
        if not os.path.exists(file_path):
            logging.warning(f"File not found: {file_path}")
            continue
        logging.info(f"Processing file: {file_path}")
        try:
            with open_log_file(file_path) as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    record = parse_audit_line(line)
                    if not record:
                        logging.debug("Skipping unrecognized line: " + line)
                        continue
                    if filter_fim_record(record, args):
                        all_records.append(record)
        except Exception as e:
            logging.error(f"Error processing file {file_path}: {e}")

    if not all_records:
        logging.info("No FIM-related audit records found matching the specified criteria.")
    else:
        output_records(all_records, args)

if __name__ == "__main__":
    main()
